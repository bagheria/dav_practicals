---
title: "Unsupervised learning: PCA & CA"
params:
  answers: false
mainfont: Arial
fontsize: 12pt
urlcolor: blue
output: 
  html_document:
    toc: true
    toc_depth: 1
    toc_float: true
    df_print: paged
    theme: paper
    # pandoc_args: --output=unsupervised_learning_1_answers.html
  pdf_document:
    toc: true
    toc_depth: 1
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
In this practical, we will learn how to use principal components analysis and correspondence analysis.

We will use the package `ca`. For this, you will probably need to `install.packages("ca")` before running the `library()` functions.

```{r packages, warning = FALSE, message = FALSE}
library(ISLR)
library(tidyverse)
library(ca)
```


```{r seed, include = FALSE}
set.seed(45)
```

# Principal components analysis

---

1. __Load the questionnaire dataset and explore it.__

---

```{r load, message = FALSE, include = params$answers}
ques_df <- read_csv("data/questionnaire.csv")

ques_df

# a lot of likert scale variables and then one sex variable
```

 
---

2. __Create a data frame with only the questionnaire columns, and standardise the dataset__

---

```{r df_cols, include = params$answers}

ques_scaled <- 
  ques_df %>% 
  select(-sex) %>% 
  scale() %>% 
  as_tibble()

# optionally, we can also compare datasets to see what happened.
bubble_plot <- function(df) {
  df %>% 
    gather(key = Question, value = Answer) %>% 
    mutate(Question = str_to_lower(Question)) %>%
    ggplot(aes(x = Question, y = Answer)) + 
    geom_count(colour = "#00008B") + 
    theme_minimal() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
}

# Unscaled
ques_df %>% 
  select(-sex) %>%
  bubble_plot() + 
  ggtitle("Unscaled")

# Scaled
ques_scaled %>% 
  bubble_plot() + 
  labs(y = "Z-score", 
       title = "Scaled")

```

---

3. __Use the `prcomp()` function to create a principal components analysis for the scaled dataset. Save the result as `pca_mod`.__

---

```{r pca, include = params$answers}
# use prcomp here?
pca_mod <- prcomp(ques_scaled)
```

---

4. __Are the first two principal components successful in explaining variance in the dataset? How many components do we need to explain 50% of the variation in the dataset?__

---

```{r expl, include = params$answers}

summary(pca_mod)
# Together, the first two components explain 35% of the variance in the dataset.
# We would need 5 components to explain 50% of the variance in the dataset.

```

---

5. __Which original variable is most related to the first principal component? Which is the least relevant for the first principal component?__

---

```{r rel, include = params$answers}
loadings_pc1 <- pca_mod$rotation[, 1]

loadings_pc1[which.max(abs(loadings_pc1))]
# BIGF13 is the most related.

loadings_pc1[which.min(abs(loadings_pc1))]
# EMPATHY4 is the least related.
```

---

6. __Create a scatter plot of the first two principal components. Map the sex of the respondents to the `colour` aesthetic. Is there a sex difference?__

---


```{r plot, include = params$answers}

as_tibble(pca_mod$x) %>% 
  ggplot(aes(x = PC1, y = PC2, colour = ques_df$sex)) +
  geom_point() +
  theme_minimal() +
  scale_colour_viridis_d()

# There does not seem to be a sex difference in the first two components

```

# Correspondence analysis

We've preprocessed a dataset from kaggle on song lyrics for the purpose of this practical. You can find the original dataset [here](https://www.kaggle.com/mousehead/songlyrics) or in the `data/` directory. If you want to know which preprocessing steps have been used and how it has been saved, you can take a look at the file `data/song_data_preproc.R`.

The `songs_ca` dataset is stored as a `.RData` file, a native file format from `R` which efficiently stores any `R` object. The `load()` function immediately loads the dataset `songs_ca` into your environment.

---

7. __Load the preprocessed `songs_ca` dataset into the environment from the `data/songs_ca.RData` file.__

---

```{r loadca, include = params$answers}
load("data/songs_ca.RData")
```


---

8. __Use the `ca()` function from the `ca` package to create a correspondence analysis object.__

---

```{r ca1, include = params$answers}
ca_mod <- ca(songs_ca)
```


---

9. __Use the `summary()` function on this object. What can you conclude about the first two inertias? What can you say about the word "love" in this dataset?__

---

```{r sumca, include = params$answers}
summary(ca_mod)

# The result of the function summary(ca_mod) contains 3 tables:Eigenvalues, row 
# variables and column variables.

# In our analysis, the first two axes explain 59.8% of the variation. 
# Table 3: Columns contains the results for column variables:
# The principal coordinates for the first 2 dimensions (k = 1 and k = 2).
# Squared correlations (cor) and contributions (ctr) of the points. 
# The word "love" from the this table does not have any correlation and 
# contribution with dimension 2. 
# All else being equal, if two artists differ on dimension 2, the artist with a
# lower score on this dimension uses the word "love" relatively more often.

```

---

10. __Recreate using `ggplot` the biplot that results from the `plot()` method on this object. Hint: for this, you can use the `rowcoord` and `colcoord` elements of the object.__

---

```{r ggca, include = params$answers}
gg_ca <- 
  rbind(ca_mod$rowcoord[, 1:2], ca_mod$colcoord[, 1:2]) %>% 
  as_tibble() %>% 
  mutate(name = c(rownames(songs_ca), colnames(songs_ca)), 
         type = c(rep("row", 12), rep("col", 26)))

gg_ca %>%
  ggplot(aes(x = Dim1, y = Dim2, shape = type, colour = type, label = name)) +
  geom_point() +
  geom_text(hjust = 0, nudge_x = 0.05) +
  coord_fixed() +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(x = "Dimension 1", y = "Dimension 2", 
       title = "CA of popular words in songs")

```

---

11. __What can you conclude about Exo and Janis Joplin? Can you come up with reasonable explanations for this?__

---

```{r ans, include = params$answers}

# Exo is a k-pop band. Janis Joplin was born in 1943 (and a member of the 
# infamous 27 club), so her lyrics are from a different period than the other
# artists.

```

---

12. __In which ways would the plot be different if we would use different artists?__

---

```{r ans2, include = params$answers}

# It would look completely different: correspondence analysis maps
# rows and columns together. So the words will be in different places.
# For example, if the artist "high school musical" would be in the sample, 
# it would separate itself from the other artists because the word "together"
# is used a lot. Consequently, the word "together" would appear near the 
# artist. The same will happen with Cole Porter and "love".

```

# Final assignment: High-dimensional PCA using SVD

This is an advanced assignment. You will have to figure out how to create PC scores from the output of a singular value decomposition.

Principal components analysis can also be used to generate a low-dimensional number of features from a high-dimensional (p > n) dataset. One area where high-dimensional data frequently occurs is in chemometrics, assessing the properties of materials using spectroscopy [(Wikipedia link)](https://en.wikipedia.org/w/index.php?title=Near-infrared_spectroscopy&oldid=865590066).

---

13. __Load the dataset "data/corn.RData" using the function `load()`.__

---

```{r loadcorn, include = params$answers}
# Load the data. Source: http://www.eigenvector.com/data/Corn/index.html 
# converted from matlab to an R data object.
load("data/corn.RData")
```

The first four columns contain properties of the corn samples (80 corn samples were analysed) and the remaining 700 columns indicate the measured transmittance at different near-infrared wavelengths. You can find more information about this dataset at [the source website](http://www.eigenvector.com/data/Corn/index.html).

Here is a plot of wavelength versus transmittance, with one line for each of the 80 corn samples:

```{r cornplot}
t(corn[, -c(1:4)]) %>% 
  as_tibble %>% 
  gather(key = corn, value = signal) %>% 
  mutate(wavelength = rep(seq(1100, 2498, 2), 80)) %>% 
  ggplot(aes(x = wavelength, y = signal, colour = corn)) +
  geom_line() +
  theme_minimal() +
  scale_colour_viridis_d(guide = "none") +
  labs(x = "Wavelength (nm)",
       y = "Transmittance",
       title = "NIR Spectroscopy of 80 corn samples")
```


---

14. __Use the `svd()` function to run a principal components analysis on the spectroscopy part of the corn dataset. Save the PC scores and plot the first two principal components. Create four plots, each mapping one of the four properties to the `colour` aesthetic. Which of the properties relate most to the first two principal components? Base your answer on the plots only. Then, do the same thing for PCs 5 and 6.__

---


```{r svdpca, include = params$answers}
# see https://stats.stackexchange.com/a/134283 for information.

# Perform svd-pca
x_scaled  <- scale(corn[, -c(1:4)], scale = FALSE)
svd_corn  <- svd(x_scaled)
pc_scores <- svd_corn$u %*% diag(svd_corn$d) 

# Plot first two principal components versus the corn properties 
ggcorn <-
  corn[, 1:4] %>%
  bind_cols(tibble(PC1 = pc_scores[, 1], 
                   PC2 = pc_scores[, 2], 
                   PC5 = pc_scores[, 5], 
                   PC6 = pc_scores[, 6]))

cowplot::plot_grid(
  ggcorn %>% 
    ggplot(aes(x = PC1, y = PC2, colour = Moisture)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c(),
  ggcorn %>% 
    ggplot(aes(x = PC1, y = PC2, colour = Oil)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c(),
  ggcorn %>% 
    ggplot(aes(x = PC1, y = PC2, colour = Protein)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c(),
  ggcorn %>% 
    ggplot(aes(x = PC1, y = PC2, colour = Starch)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c()
)

# Moisture and oil seem to have a strong relation with the first two PCs, 
# and their high values are on opposite sides.
# The high/low values for protein and starch seem more randomly 
# ordered in these plots. 

cowplot::plot_grid(
  ggcorn %>% 
    ggplot(aes(x = PC5, y = PC6, colour = Moisture)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c(),
  ggcorn %>% 
    ggplot(aes(x = PC5, y = PC6, colour = Oil)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c(),
  ggcorn %>% 
    ggplot(aes(x = PC5, y = PC6, colour = Protein)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c(),
  ggcorn %>% 
    ggplot(aes(x = PC5, y = PC6, colour = Starch)) +
    geom_point() +
    theme_minimal() + 
    scale_colour_viridis_c()
)

# Here, it's protein and starch that relate more to the PCs. They too are 
# opposites in these samples.
```
